{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLy2OXnqbOWg"
   },
   "source": [
    "## Before you run this notebook:\n",
    "1. Please make sure that you have the \"HCV-Egy-Data.csv\" file at the same folder of this notebook. If not, please modify the first code cell (right below) accordingly.\n",
    "2. If you are running on Google's Colab, you may need to mount the Google drive as your storage. Follow the instruction given by Google. \n",
    "\n",
    "3. If you are running on a local environment, please comment out the first block inside the very first code cell.\n",
    "\n",
    "4. If you already have the fabricated data file, please modify the conresponding parameter in the first code cell.\n",
    "\n",
    "5. The source of the original data is at: [UC Irvine Machine Learining Repository: Hepatitis C Virus (HCV) for Egyptian patients Data Set](https://archive.ics.uci.edu/ml/datasets/Hepatitis+C+Virus+%28HCV%29+for+Egyptian+patients\n",
    ")\n",
    "\n",
    "## When you run this code:\n",
    "1. You may find the number of entries is very limited, so the results of an array of clasiifiers are only marginally better than a random guess. The reason of this ineffectiveness is, according to my guess, due to the limited amount of data and my lack of domain knowledge to implememnt a rule-based classifier or something better. \n",
    "\n",
    "2. Despite of the low accuracy, I listed some of the most important features and you could select them for the training. I recommend that you run the whole notebook first so you would get the main logical flow of this document to better assist you modify to your needs. \n",
    "\n",
    "3. Since the main purpose of this portion is to help wih the data fabrication. As soon as you have the fabricated data, you could run the classifier on the fabriicated data to check if the accuracy score is close to that on the true dataset. \n",
    "\n",
    "4. There is a paper on implementibg a complex classifier for this specific problem. [A novel model based on non invasive methods for prediction of liver fibrosis](https://ieeexplore.ieee.org/document/8289800).  The discretization part of the dataset below is based on the knowledge provided in this paper. However, I was not able to achieve the accuracy from this paper. The knowledge required in duplicating their result is beyond the scope of this course (CMPE 256 in SJSU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "50VcD_kkBtsV",
    "outputId": "ea9fe541-d1eb-4d6b-f56f-7f3d3360912d"
   },
   "outputs": [],
   "source": [
    "## ------ Comment this block if run on local machine -----###\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "## ----------------  Block ends  --------------#####\n",
    "\n",
    "\n",
    "#------ Change below parameters if necessary --------# \n",
    "#path = \"/content/drive/My Drive/Colab Notebooks/\" # change path here \n",
    "path = 'C:/Users/swlee/Desktop/syn_models/'\n",
    "#source_data_file_name = \"HCV-Egy-Data.csv\"\n",
    "source_data_file_name = 'hcv.csv'\n",
    "## ----------------  Block ends  --------------#####\n",
    "\n",
    "csv_file_path = path + source_data_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtrroFxaBrSn"
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "## Utility tools \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "\n",
    "## Models \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "## Analysis tools \n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score, make_scorer\n",
    "from sklearn import model_selection\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "## Warning settings \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def plot_test_result(clfs, test_score, test_scores):\n",
    "    names = []\n",
    "    for i in range(0, len(clfs)): \n",
    "        clf = clfs[i]\n",
    "        clf_name = clf.__class__.__name__\n",
    "        names.append(clf_name)\n",
    "\n",
    "    y_pos = np.arange(len(names))\n",
    "\n",
    "    plt.barh(y_pos, test_scores, align='center')\n",
    "    plt.yticks(y_pos, names)\n",
    "    plt.xlim(0.0, 0.99)\n",
    "    plt.xlabel('Score')\n",
    "    plt.title('Test Data Accuracy Scores')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Splitting the data into Train and Test data sets\n",
    "def train_models():\n",
    "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, stratify = labels, random_state=42)\n",
    "  ## Initializing all models and parameters\n",
    "  #Initializing classifiers\n",
    "  RF_clf = RandomForestClassifier(n_estimators = 30, random_state = 1, class_weight = 'balanced')\n",
    "  AB_clf = AdaBoostClassifier(n_estimators = 30, random_state = 2)\n",
    "  MLP_clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2))\n",
    "  KNN_clf = KNeighborsClassifier()\n",
    "  LOG_clf = linear_model.LogisticRegression(multi_class = \"ovr\", solver = \"sag\", class_weight = 'balanced')\n",
    "  GNB_clf = GaussianNB()\n",
    "  SVM_clf = svm.SVC(gamma='scale', probability=True)\n",
    "  clfs = [RF_clf, AB_clf, MLP_clf, KNN_clf, LOG_clf, GNB_clf, SVM_clf]\n",
    "\n",
    "  #Specficying scorer and parameters for grid search\n",
    "  feature_len = features.shape[1]\n",
    "  print(\"Number of selected features:\", feature_len)\n",
    "  scorer = make_scorer(accuracy_score)\n",
    "\n",
    "  pca_n_components = (list)(range(4, feature_len, 3))\n",
    "  pca_n_components.append(feature_len)\n",
    "\n",
    "  parameters_RF = {'clf__max_features': ['auto', 'log2'], \n",
    "                  'pca__n_components': pca_n_components}\n",
    "  parameters_AB = {'clf__learning_rate': np.linspace(0.5, 2, num=10), \n",
    "                  'pca__n_components': pca_n_components}\n",
    "  parameters_MLP = {'pca__n_components': pca_n_components}\n",
    "  parameters_KNN = {'clf__n_neighbors': [10, 20, 30, 40, 50, 60], \n",
    "                    'pca__n_components': pca_n_components}\n",
    "  parameters_LOG = {'clf__C': np.logspace(1, 1000, 5), \n",
    "                    'pca__n_components': pca_n_components}\n",
    "  parameters_GNB = {'pca__n_components': pca_n_components}\n",
    "  parameters_SVM = {'pca__n_components': pca_n_components}\n",
    "\n",
    "  parameters = {clfs[0]: parameters_RF,\n",
    "                clfs[1]: parameters_AB,\n",
    "                clfs[2]: parameters_MLP,\n",
    "                clfs[3]: parameters_KNN,\n",
    "                clfs[4]: parameters_LOG,\n",
    "                clfs[5]: parameters_GNB,\n",
    "                clfs[6]: parameters_SVM}\n",
    "\n",
    "  #Initializing PCA\n",
    "  pca = PCA()\n",
    "\n",
    "  #Creating cross validation data splits\n",
    "  cv_sets = model_selection.StratifiedShuffleSplit(n_splits = 3, test_size = 0.25, random_state=42)\n",
    "\n",
    "  #Initialize result storage\n",
    "  clfs_return = []\n",
    "  dm_reduce_return = []\n",
    "  train_scores = []\n",
    "  test_scores = []\n",
    "\n",
    "  #Loop through classifiers\n",
    "  for clf in clfs:\n",
    "\n",
    "      estimators = [('pca', pca), ('clf', clf)]\n",
    "      pipeline = Pipeline(estimators)\n",
    "      \n",
    "      print(\"Training a {} with {}...\".format(clf.__class__.__name__, pca.__class__.__name__))\n",
    "      start = time()\n",
    "      \n",
    "      #Grid search over pipeline and return best classifier\n",
    "      grid = model_selection.GridSearchCV(pipeline, param_grid = parameters[clf], scoring = scorer, cv = cv_sets, n_jobs = -1)\n",
    "      grid.fit(X_train, y_train)\n",
    "      best_pipe = grid.best_estimator_\n",
    "      #clf = CalibratedClassifierCV(best_pipe.named_steps['clf'], cv= 'prefit', method='isotonic')\n",
    "      clf.fit(best_pipe.named_steps['pca'].transform(X_train), y_train)\n",
    "      dm_reduce = best_pipe.named_steps['pca']\n",
    "      \n",
    "      end = time()\n",
    "      print(\"Trained {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "      \n",
    "      #Make predictions of train data\n",
    "      y_train_pred = clf.predict(best_pipe.named_steps['pca'].transform(X_train))\n",
    "      train_score = accuracy_score(y_train.values, y_train_pred)\n",
    "      print(\"Score of {} for train set: {:.4f}.\".format(clf.__class__.__name__, train_score))\n",
    "      \n",
    "      #Make predictions of test data\n",
    "      y_test_pred = clf.predict(best_pipe.named_steps['pca'].transform(X_test))\n",
    "      test_score = accuracy_score(y_test.values, y_test_pred)\n",
    "      print(\"Score of {} for test set: {:.4f}.\".format(clf.__class__.__name__, test_score))\n",
    "      \n",
    "      #Append the result to storage            \n",
    "      clfs_return.append(clf)\n",
    "      dm_reduce_return.append(dm_reduce)\n",
    "      train_scores.append(train_score)\n",
    "      test_scores.append(test_score)\n",
    "\n",
    "  plot_test_result(clfs, test_score, test_scores)\n",
    "\n",
    "  #Defining the best classifier\n",
    "  best_clf = clfs_return[np.argmax(test_scores)]\n",
    "  best_dm_reduce = dm_reduce_return[np.argmax(test_scores)]\n",
    "  print(\"The best classifier is {}\".format(best_clf.__class__.__name__))\n",
    "\n",
    "  return [best_clf,best_dm_reduce]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "59ukXwPtk7zA",
    "outputId": "72c3d4ca-de1a-45d7-dff8-38d01621c923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Read In True Data----------\n",
      "   Age  Gender  Bmi  Fever  Nausea/Vomiting  Headache  Diarrhea  \\\n",
      "0   56       0   35      1                0         0         0   \n",
      "1   46       0   29      0                1         1         0   \n",
      "2   57       0   33      1                1         1         1   \n",
      "3   49       1   33      0                1         0         1   \n",
      "4   59       0   32      0                0         1         0   \n",
      "\n",
      "   Fatigue and Bone-ache  Jaundice  Epigastric pain  ...  ALT 36  ALT 48  \\\n",
      "0                      1         1                1  ...       5       5   \n",
      "1                      1         1                0  ...      57     123   \n",
      "2                      0         0                0  ...       5       5   \n",
      "3                      0         1                0  ...      48      77   \n",
      "4                      1         1                1  ...      94      90   \n",
      "\n",
      "   ALT after 24w  RNA Base   RNA 4   RNA 12  RNA EOT  RNA EF  \\\n",
      "0              5    655330  634536   288194        5       5   \n",
      "1             44     40620  538635   637056   336804   31085   \n",
      "2              5    571148  661346        5   735945  558829   \n",
      "3             33   1041941  449939   585688   744463  582301   \n",
      "4             30    660410  738756  3731527   338946  242861   \n",
      "\n",
      "   Baseline histological grading  Baseline histological staging  \n",
      "0                             13                              2  \n",
      "1                              4                              2  \n",
      "2                              4                              4  \n",
      "3                             10                              3  \n",
      "4                             11                              1  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "------OK!----------\n",
      "\n",
      "\n",
      "\n",
      "------Define features and label(s)----------\n",
      "------OK!----------\n",
      "\n",
      "\n",
      "\n",
      "number of features: 28\n",
      "\n",
      "\n",
      "\n",
      "Unique values of label are: [2 4 3 1]\n",
      "\n",
      "\n",
      "number of unique values in labels is 4\n",
      "\n",
      "\n",
      "\n",
      "------Examine label counts (balanced or not?)---------\n",
      "Count of Stage 1:  336\n",
      "Count of Stage 2:  332\n",
      "Count of Stage 3:  355\n",
      "Count of Stage 4:  362\n",
      "------OK!----------\n",
      "\n",
      "\n",
      "\n",
      "------Inspect 10 most important feautures and print out the top 4----------\n",
      "              Specs     Score\n",
      "2               Bmi  4.045028\n",
      "26           RNA EF  2.441724\n",
      "1            Gender  2.227700\n",
      "9   Epigastric pain  2.188360\n",
      "------OK!----------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('------Read In True Data----------')\n",
    "headers = ['Age', 'Gender', 'Bmi', 'Fever', 'Nausea/Vomiting', 'Headache',\\\n",
    "           'Diarrhea', 'Fatigue and Bone-ache', 'Jaundice', 'Epigastric pain', 'WBC',\\\n",
    "           'RBC', 'HGB', 'Plat', 'AST 1', 'ALT 1',\\\n",
    "           'ALT 4', 'ALT 12', 'ALT 24', 'ALT 36', 'ALT 48', 'ALT after 24w',\\\n",
    "           'RNA Base', 'RNA 4', 'RNA 12', 'RNA EOT', 'RNA EF',\\\n",
    "           'Baseline histological grading', 'Baseline histological staging']\n",
    "\n",
    "csv_data = pd.read_csv(csv_file_path, skiprows=1, names=headers)\n",
    "print(csv_data.head())\n",
    "print('------OK!----------\\n\\n\\n')\n",
    "\n",
    "print('------Define features and label(s)----------')\n",
    "feature_cols = ['Age', 'Gender', 'Bmi', 'Fever', 'Nausea/Vomiting', 'Headache',\\\n",
    "           'Diarrhea', 'Fatigue and Bone-ache', 'Jaundice', 'Epigastric pain', 'WBC',\\\n",
    "           'RBC', 'HGB', 'Plat', 'AST 1', 'ALT 1',\\\n",
    "           'ALT 4', 'ALT 12', 'ALT 24', 'ALT 36', 'ALT 48', 'ALT after 24w',\\\n",
    "           'RNA Base', 'RNA 4', 'RNA 12', 'RNA EOT', 'RNA EF',\\\n",
    "           'Baseline histological grading']\n",
    "features = csv_data[feature_cols]\n",
    "\n",
    "label_col = ['Baseline histological staging']\n",
    "labels = csv_data[label_col]\n",
    "print('------OK!----------\\n\\n\\n')\n",
    "\n",
    "\n",
    "num_of_features = features.shape[1]\n",
    "print(\"number of features:\", num_of_features)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Unique values of label are:\", pd.unique(labels['Baseline histological staging']))\n",
    "print(\"\\n\")\n",
    "print(\"number of unique values in labels is\" , len(pd.unique(labels['Baseline histological staging'])))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print('------Examine label counts (balanced or not?)---------')\n",
    "print(\"Count of Stage 1: \", csv_data[csv_data[\"Baseline histological staging\"] == 1].shape[0])\n",
    "print(\"Count of Stage 2: \", csv_data[csv_data[\"Baseline histological staging\"] == 2].shape[0])\n",
    "print(\"Count of Stage 3: \", csv_data[csv_data[\"Baseline histological staging\"] == 3].shape[0])\n",
    "print(\"Count of Stage 4: \", csv_data[csv_data[\"Baseline histological staging\"] == 4].shape[0])\n",
    "print('------OK!----------\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('------Inspect 10 most important feautures and print out the top 4----------')\n",
    "X = features\n",
    "y = labels\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "result_df = featureScores.nlargest(4,'Score')\n",
    "print(result_df)\n",
    "print('------OK!----------\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "QoC1TL5b060E",
    "outputId": "6c57f666-20b0-40ed-c23c-f308e9d25c26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Bmi</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Nausea/Vomiting</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Fatigue and Bone-ache</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Epigastric pain</th>\n",
       "      <th>...</th>\n",
       "      <th>ALT 24</th>\n",
       "      <th>ALT 36</th>\n",
       "      <th>ALT 48</th>\n",
       "      <th>ALT after 24w</th>\n",
       "      <th>RNA Base</th>\n",
       "      <th>RNA 4</th>\n",
       "      <th>RNA 12</th>\n",
       "      <th>RNA EOT</th>\n",
       "      <th>RNA EF</th>\n",
       "      <th>Baseline histological grading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age  Gender Bmi  Fever  Nausea/Vomiting  Headache  Diarrhea  \\\n",
       "0   5       0   4      1                0         0         0   \n",
       "1   3       0   2      0                1         1         0   \n",
       "2   5       0   3      1                1         1         1   \n",
       "3   4       1   3      0                1         0         1   \n",
       "4   6       0   3      0                0         1         0   \n",
       "\n",
       "   Fatigue and Bone-ache  Jaundice  Epigastric pain  ... ALT 24 ALT 36  \\\n",
       "0                      1         1                1  ...      2      0   \n",
       "1                      1         1                0  ...      2      2   \n",
       "2                      0         0                0  ...      2      0   \n",
       "3                      0         1                0  ...      2      2   \n",
       "4                      1         1                1  ...      2      2   \n",
       "\n",
       "   ALT 48 ALT after 24w RNA Base RNA 4 RNA 12 RNA EOT RNA EF  \\\n",
       "0       0             0        1     1      1       0      0   \n",
       "1       2             2        1     1      1       1      1   \n",
       "2       0             0        1     1      0       1      1   \n",
       "3       2             1        1     1      1       1      1   \n",
       "4       2             1        1     1      1       1      1   \n",
       "\n",
       "  Baseline histological grading  \n",
       "0                            13  \n",
       "1                             4  \n",
       "2                             4  \n",
       "3                            10  \n",
       "4                            11  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manually discretize data\n",
    "features['Age']   = pd.cut(features['Age'],   [0, 32, 37, 42, 47, 52, 57, 62, 100],   True,   labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "features['Bmi']   = pd.cut(features['Bmi'],   [0, 18.5, 25, 30, 35, 40],              False,  labels=[0, 1, 2, 3, 4])\n",
    "features['WBC']   = pd.cut(features['WBC'],   [0, 4000, 11000, 13000],                True,   labels=[0, 1, 2])\n",
    "features['RBC']   = pd.cut(features['RBC'],   [0, 3000000, 5000000, 8000000],         False,  labels=[0, 1, 2])\n",
    "features['Plat']  = pd.cut(features['Plat'],  [0, 100000, 255000, 300000],            False,  labels=[0, 1, 2])\n",
    "\n",
    "\n",
    "features['AST 1'] = pd.cut(features['AST 1'],                 [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT 1'] = pd.cut(features['ALT 1'],                 [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT 4'] = pd.cut(features['ALT 4'],                 [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT 12'] = pd.cut(features['ALT 12'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT 24'] = pd.cut(features['ALT 24'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT 36'] = pd.cut(features['ALT 36'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT 48'] = pd.cut(features['ALT 48'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "features['ALT after 24w'] = pd.cut(features['ALT after 24w'], [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "\n",
    "\n",
    "features['RNA Base'] =  pd.cut(features['RNA Base'],  [0, 5, 9000000], True, labels=[0, 1])\n",
    "features['RNA 4'] =     pd.cut(features['RNA 4'],     [0, 5, 9000000], True, labels=[0, 1])\n",
    "features['RNA 12'] =    pd.cut(features['RNA 12'],    [0, 5, 9000000], True, labels=[0, 1])\n",
    "features['RNA EOT'] =   pd.cut(features['RNA EOT'],   [0, 5, 9000000], True, labels=[0, 1])\n",
    "features['RNA EF'] =    pd.cut(features['RNA EF'],    [0, 5, 9000000], True, labels=[0, 1])\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drsMHAXT3rkd"
   },
   "outputs": [],
   "source": [
    "## !!!! Modify the features you want to select !!!! ### \n",
    "selected_features_cols = []\n",
    "\n",
    "if len(selected_features_cols) >= 1:\n",
    "  features = csv_data[selected_features_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "colab_type": "code",
    "id": "iW7b-fQlDa0Q",
    "outputId": "ce884224-be59-4317-8715-9e9b3f3f636b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected features: 28\n",
      "Training a RandomForestClassifier with PCA...\n",
      "Trained RandomForestClassifier in 0.1 minutes\n",
      "Score of RandomForestClassifier for train set: 1.0000.\n",
      "Score of RandomForestClassifier for test set: 0.2419.\n",
      "Training a AdaBoostClassifier with PCA...\n",
      "Trained AdaBoostClassifier in 0.1 minutes\n",
      "Score of AdaBoostClassifier for train set: 0.4125.\n",
      "Score of AdaBoostClassifier for test set: 0.2274.\n",
      "Training a MLPClassifier with PCA...\n",
      "Trained MLPClassifier in 0.1 minutes\n",
      "Score of MLPClassifier for train set: 0.3132.\n",
      "Score of MLPClassifier for test set: 0.2671.\n",
      "Training a KNeighborsClassifier with PCA...\n",
      "Trained KNeighborsClassifier in 0.1 minutes\n",
      "Score of KNeighborsClassifier for train set: 0.4937.\n",
      "Score of KNeighborsClassifier for test set: 0.1949.\n",
      "Training a LogisticRegression with PCA...\n",
      "Trained LogisticRegression in 0.1 minutes\n",
      "Score of LogisticRegression for train set: 0.3195.\n",
      "Score of LogisticRegression for test set: 0.2635.\n",
      "Training a GaussianNB with PCA...\n",
      "Trained GaussianNB in 0.0 minutes\n",
      "Score of GaussianNB for train set: 0.3195.\n",
      "Score of GaussianNB for test set: 0.2491.\n",
      "Training a SVC with PCA...\n",
      "Trained SVC in 0.1 minutes\n",
      "Score of SVC for train set: 0.4224.\n",
      "Score of SVC for test set: 0.2563.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best classifier is MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "res = train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "uRQP03gyNPlW",
    "outputId": "4fd2b7ed-4873-4312-ef1d-6be4bb7ef283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the best classifier on all true data is 0.303971119133574\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Accuracy score of the best classifier on all the true data.\n",
    "best_clf = res[0]\n",
    "best_dm_reduce = res[1]\n",
    "all_pred_result = best_clf.predict(best_dm_reduce.transform(features))\n",
    "accu_score = accuracy_score(labels, all_pred_result)\n",
    "print(\"The accuracy score of the best classifier on all true data is\", accu_score)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKkHTuNsWFcg"
   },
   "source": [
    "## **Continue to run if you have set up the fabricated file path name at the very top! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(fab_features):\n",
    "    fab_features['Age']   = pd.cut(fab_features['Age'],   [0, 32, 37, 42, 47, 52, 57, 62, 100],   True,   labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    fab_features['Bmi']   = pd.cut(fab_features['Bmi'],   [0, 18.5, 25, 30, 35, 40],              False,  labels=[0, 1, 2, 3, 4])\n",
    "    fab_features['WBC']   = pd.cut(fab_features['WBC'],   [0, 4000, 11000, 13000],                True,   labels=[0, 1, 2])\n",
    "    fab_features['RBC']   = pd.cut(fab_features['RBC'],   [0, 3000000, 5000000, 8000000],         False,  labels=[0, 1, 2])\n",
    "    fab_features['Plat']  = pd.cut(fab_features['Plat'],  [0, 100000, 255000, 300000],            False,  labels=[0, 1, 2])\n",
    "\n",
    "\n",
    "    fab_features['AST 1'] = pd.cut(fab_features['AST 1'],                 [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT 1'] = pd.cut(fab_features['ALT 1'],                 [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT 4'] = pd.cut(fab_features['ALT 4'],                 [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT 12'] = pd.cut(fab_features['ALT 12'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT 24'] = pd.cut(fab_features['ALT 24'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT 36'] = pd.cut(fab_features['ALT 36'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT 48'] = pd.cut(fab_features['ALT 48'],               [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "    fab_features['ALT after 24w'] = pd.cut(fab_features['ALT after 24w'], [0, 20, 40, 200], False, labels=[0, 1, 2])\n",
    "\n",
    "\n",
    "    fab_features['RNA Base'] =  pd.cut(fab_features['RNA Base'],  [0, 5, 9000000], True, labels=[0, 1])\n",
    "    fab_features['RNA 4'] =     pd.cut(fab_features['RNA 4'],     [0, 5, 9000000], True, labels=[0, 1])\n",
    "    fab_features['RNA 12'] =    pd.cut(fab_features['RNA 12'],    [0, 5, 9000000], True, labels=[0, 1])\n",
    "    fab_features['RNA EOT'] =   pd.cut(fab_features['RNA EOT'],   [0, 5, 9000000], True, labels=[0, 1])\n",
    "    fab_features['RNA EF'] =    pd.cut(fab_features['RNA EF'],    [0, 5, 9000000], True, labels=[0, 1])\n",
    "    \n",
    "    return fab_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on original data is: 0.303971119133574\n",
      "The accuracy score on fabricated data is: 0.2571428571428571\n"
     ]
    }
   ],
   "source": [
    "fabricated_data_file_name = 'synth1.csv'\n",
    "fabricated_file_path = path + fabricated_data_file_name\n",
    "\n",
    "if len(fabricated_data_file_name) > 0:\n",
    "    fab_data = pd.read_csv(fabricated_file_path, skiprows=1, names=headers)\n",
    "\n",
    "    fab_features = fab_data[feature_cols]\n",
    "    fab_labels = fab_data[label_col]\n",
    "    \n",
    "    fab_features[fab_features < 0] = 5\n",
    "    \n",
    "    fab_features = discretize(fab_features)\n",
    "\n",
    "    fab_pred = best_clf.predict(best_dm_reduce.transform(fab_features))\n",
    "    fab_accu_score = accuracy_score(fab_labels, fab_pred)\n",
    "    print(\"The accuracy score on original data is:\", accu_score)\n",
    "    print(\"The accuracy score on fabricated data is:\", fab_accu_score)\n",
    "else:\n",
    "    print(\"Fabricated data file undefined. Please set up the path and file name at the very top of this file.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on original data is: 0.303971119133574\n",
      "The accuracy score on fabricated data is: 0.30357142857142855\n"
     ]
    }
   ],
   "source": [
    "fabricated_data_file_name = 'synth2.csv'\n",
    "fabricated_file_path = path + fabricated_data_file_name\n",
    "\n",
    "if len(fabricated_data_file_name) > 0:\n",
    "    fab_data = pd.read_csv(fabricated_file_path, skiprows=1, names=headers)\n",
    "\n",
    "    fab_features = fab_data[feature_cols]\n",
    "    fab_labels = fab_data[label_col]\n",
    "    \n",
    "    fab_features[fab_features < 0] = 5\n",
    "    \n",
    "    fab_features = discretize(fab_features)\n",
    "\n",
    "    fab_pred = best_clf.predict(best_dm_reduce.transform(fab_features))\n",
    "    fab_accu_score = accuracy_score(fab_labels, fab_pred)\n",
    "    print(\"The accuracy score on original data is:\", accu_score)\n",
    "    print(\"The accuracy score on fabricated data is:\", fab_accu_score)\n",
    "else:\n",
    "    print(\"Fabricated data file undefined. Please set up the path and file name at the very top of this file.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on original data is: 0.303971119133574\n",
      "The accuracy score on fabricated data is: 0.28\n"
     ]
    }
   ],
   "source": [
    "fabricated_data_file_name = 'synth3.csv'\n",
    "fabricated_file_path = path + fabricated_data_file_name\n",
    "\n",
    "if len(fabricated_data_file_name) > 0:\n",
    "    fab_data = pd.read_csv(fabricated_file_path, skiprows=1, names=headers)\n",
    "\n",
    "    fab_features = fab_data[feature_cols]\n",
    "    fab_labels = fab_data[label_col]\n",
    "    \n",
    "    fab_pred = best_clf.predict(best_dm_reduce.transform(fab_features))\n",
    "    fab_accu_score = accuracy_score(fab_labels, fab_pred)\n",
    "    print(\"The accuracy score on original data is:\", accu_score)t\n",
    "    print(\"The accuracy score on fabricated data is:\", fab_accu_score)\n",
    "else:\n",
    "    print(\"Fabricated data file undefined. Please set up the path and file name at the very top of this file.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifier_Draft.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
